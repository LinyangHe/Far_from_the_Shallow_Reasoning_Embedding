{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pca_components = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera-ready version\n",
    "subject_list = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\"]\n",
    "name_base_layer_key_list = [('50_0_6', 'layer_0'),  #lexicon\n",
    "                            ('50_0_6', 'residual'), #syntax\n",
    "                        ('50_6_20', 'residual'), #meaning\n",
    "                        ('50_20_30', 'layer_30'),  #reasoning\n",
    "                        ('50_20_30', 'residual')] #full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slurm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\"]\n",
    "for subj in subject_list:\n",
    "    for name_base, layer_key in name_base_layer_key_list:\n",
    "        sbatch_file_name = f\"sf_{name_base}_{layer_key}_{subj}.sh\"\n",
    "        with open(sbatch_file_name, 'w', newline='\\n') as f:\n",
    "            f.write(\"#!/bin/bash\\n\")\n",
    "            f.write(f\"#SBATCH --job-name={subj}_{name_base}_{layer_key}\\n\")\n",
    "            f.write(f\"#SBATCH --output=log_{subj}_{name_base}_{layer_key}.txt\\n\")\n",
    "            f.write(f\"#SBATCH --error=err_{subj}_{name_base}_{layer_key}.txt\\n\")\n",
    "            f.write(\"#SBATCH --mem=128G\\n\")\n",
    "            f.write(\"#SBATCH --cpus-per-task=1\\n\")\n",
    "            f.write(\"#SBATCH --partition=naplab,burst\\n\")\n",
    "            f.write(f\"python -u shuffle.py --name_base {name_base} --layer_key {layer_key} --subj {subj} --pca_components {pca_components}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "bash_file_name = \"sf_good_layer.sh\"\n",
    "\n",
    "with open(bash_file_name, 'w', newline='\\n') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(f\"# Auto-generated at {datetime.now()}\\n\")\n",
    "    f.write(\"set -e  # exit when any command fails\\n\\n\")   #\n",
    "\n",
    "    for subj in subject_list:\n",
    "        for name_base, layer_key in name_base_layer_key_list:\n",
    "            sbatch_file_name = f\"./sf_{name_base}_{layer_key}_{subj}.sh\"\n",
    "            f.write(f\"echo 'Submitting {sbatch_file_name}'\\n\")\n",
    "            f.write(f\"sbatch {sbatch_file_name}\\n\")\n",
    "\n",
    "os.chmod(bash_file_name, 0o755)\n",
    "\n",
    "print(\"Generated bash successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jupyter version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Run shuffle locally inside the notebook without submitting to Slurm.\n",
    "log_dir = Path(\"./shuffle_logs\")\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "subject_list = [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\"]\n",
    "for subj in subject_list:\n",
    "    for name_base, layer_key in name_base_layer_key_list:\n",
    "        log_file = log_dir / f\"shuffle_{subj}_{name_base}_{layer_key}.txt\"\n",
    "        cmd = [\n",
    "            \"python\",\"-u\",\"shuffle.py\",\n",
    "            \"--name_base\", name_base,\n",
    "            \"--layer_key\", layer_key,\n",
    "            \"--subj\", subj,\n",
    "            \"--pca_components\", str(pca_components)\n",
    "        ]\n",
    "        print(f\"Running {' '.join(cmd)}\")\n",
    "        with log_file.open(\"w\") as lf:\n",
    "            subprocess.run(cmd, check=True, stdout=lf, stderr=subprocess.STDOUT)\n",
    "        print(f\"✔ Saved log to {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slurm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pca_components in [500]:\n",
    "    for name_base, layer_key in name_base_layer_key_list:\n",
    "        sbatch_file_name = f\"encoding_{name_base}_{layer_key}_{pca_components}.sh\"\n",
    "        with open(sbatch_file_name, 'w', newline='\\n') as f:\n",
    "            f.write(\"#!/bin/bash\\n\")\n",
    "            f.write(f\"#SBATCH --job-name=pt_{name_base}_{layer_key}_{pca_components}\\n\")\n",
    "            f.write(f\"#SBATCH --output=log_pt_{name_base}_{layer_key}_{pca_components}.txt\\n\")\n",
    "            f.write(f\"#SBATCH --error=err_pt_{name_base}_{layer_key}_{pca_components}.txt\\n\")\n",
    "            f.write(\"#SBATCH --mem=128G\\n\")\n",
    "            f.write(\"#SBATCH --cpus-per-task=1\\n\")\n",
    "            f.write(\"#SBATCH --partition=naplab,burst\\n\")\n",
    "            # f.write(\"cd /home/lh3288/project/PJ2504_Dual_stream/LLM_Dual_Stream/Brain_Encoding/Hasson\\n\")\n",
    "            f.write(f\"python -u encoding.py --name_base {name_base} --layer_key {layer_key} --pca_components {pca_components}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "bash_file_name = \"encoding_all.sh\"\n",
    "\n",
    "with open(bash_file_name, 'w', newline='\\n') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    f.write(f\"# Auto-generated at {datetime.now()}\\n\")\n",
    "    f.write(\"set -e  # exit when any command fails\\n\\n\")   #\n",
    "\n",
    "    for pca_components in [500]:\n",
    "        for name_base, layer_key in name_base_layer_key_list:\n",
    "            print(name_base, layer_key)\n",
    "            sbatch_file_name = f\"./scaled_{name_base}_{layer_key}_{pca_components}.sh\"\n",
    "            f.write(f\"echo 'Submitting {sbatch_file_name}'\\n\")\n",
    "            f.write(f\"sbatch {sbatch_file_name}\\n\")\n",
    "\n",
    "os.chmod(bash_file_name, 0o755)\n",
    "\n",
    "print(\"Generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jupyter version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Run encoding locally; adjust `pca_values` for sweeps.\n",
    "encoding_log_dir = Path(\"./encoding_logs\")\n",
    "encoding_log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "pca_values = [pca_components]  # reuse the global default defined above\n",
    "for current_pca in pca_values:\n",
    "    for name_base, layer_key in name_base_layer_key_list:\n",
    "        log_file = encoding_log_dir / f\"encoding_{name_base}_{layer_key}_{current_pca}.txt\"\n",
    "        cmd = [\n",
    "            \"python\",\"-u\",\"encoding.py\",\n",
    "            \"--name_base\", name_base,\n",
    "            \"--layer_key\", layer_key,\n",
    "            \"--pca_components\", str(current_pca)\n",
    "        ]\n",
    "        print(f\"Running {' '.join(cmd)}\")\n",
    "        with log_file.open(\"w\") as lf:\n",
    "            subprocess.run(cmd, check=True, stdout=lf, stderr=subprocess.STDOUT)\n",
    "        print(f\"✔ Saved log to {log_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
